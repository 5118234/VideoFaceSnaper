<?xml version="1.0"?>
<doc>
    <assembly>
        <name>kafka-net</name>
    </assembly>
    <members>
        <member name="T:KafkaNet.Common.AsyncLock">
            <summary>
            An asynchronous locking construct.
            </summary>
            <remarks>
            This is based on Stephen Toub's implementation here: http://blogs.msdn.com/b/pfxteam/archive/2012/02/12/10266988.aspx
            However, we're using SemaphoreSlim as the basis rather than AsyncSempahore, since in .NET 4.5 SemaphoreSlim implements the WaitAsync() method.
            </remarks>
        </member>
        <member name="T:KafkaNet.Common.BigEndianBinaryReader">
            <summary>
            A BinaryReader that is BigEndian aware binary reader.
            </summary>
            <remarks>
            Booleans, bytes and byte arrays will be written directly.
            All other values will be converted to a byte array in BigEndian byte order and written.
            Characters and Strings will all be encoded in UTF-8 (which is byte order independent).
            </remarks>
            <remarks>
            BigEndianBinaryWriter code provided by Zoltu
            https://github.com/Zoltu/Zoltu.EndianAwareBinaryReaderWriter
            
            The code was modified to provide Kafka specific logic and helper functions.
            </remarks>
        </member>
        <member name="T:KafkaNet.Common.BigEndianBinaryWriter">
            <summary>
            A BinaryWriter that stores values in BigEndian format.
            </summary>
            <remarks>
            Booleans, bytes and byte arrays will be written directly.
            All other values will be converted to a byte array in BigEndian byte order and written.
            Characters and Strings will all be encoded in UTF-8 (which is byte order independent).
            </remarks>
            <remarks>
            BigEndianBinaryWriter code provided by Zoltu
            https://github.com/Zoltu/Zoltu.EndianAwareBinaryReaderWriter
            The code was modified to implement Kafka specific byte handling.
            </remarks>
        </member>
        <member name="T:KafkaNet.Common.AsyncManualResetEvent">
            <summary>
            Async version of a manual reset event.
            </summary>
        </member>
        <member name="M:KafkaNet.Common.AsyncManualResetEvent.#ctor(System.Boolean)">
            <summary>
            Async version of a manual reset event.
            </summary>
            <param name="set">Sets whether the initial state of the event is true=open or false=blocking.</param>
        </member>
        <member name="M:KafkaNet.Common.AsyncManualResetEvent.WaitAsync">
            <summary>
            Async wait for the manual reset event to be triggered.
            </summary>
            <returns></returns>
        </member>
        <member name="M:KafkaNet.Common.AsyncManualResetEvent.Open">
            <summary>
            Set the event and complete, releasing all WaitAsync requests.
            </summary>
        </member>
        <member name="M:KafkaNet.Common.AsyncManualResetEvent.Close">
            <summary>
            Reset the event making all WaitAsync requests block, does nothing if already reset.
            </summary>
        </member>
        <member name="F:KafkaNet.Common.ScheduledTimerStatus.Stopped">
            <summary>
                Timer is stopped.
            </summary>
        </member>
        <member name="F:KafkaNet.Common.ScheduledTimerStatus.Running">
            <summary>
                Timer is running.
            </summary>
        </member>
        <member name="P:KafkaNet.Common.IScheduledTimer.Status">
            <summary>
                Current running status of the timer.
            </summary>
        </member>
        <member name="P:KafkaNet.Common.IScheduledTimer.Enabled">
            <summary>
            Indicates if the timer is running.
            </summary>
        </member>
        <member name="M:KafkaNet.Common.IScheduledTimer.StartingAt(System.DateTime)">
            <summary>
                Set the time to start a replication.
            </summary>
            <param name="start">Start date and time for the replication timer.</param>
            <returns>Instance of ScheduledTimer for fluent configuration.</returns>
            <remarks>If no interval is set, the replication will only happen once.</remarks>
        </member>
        <member name="M:KafkaNet.Common.IScheduledTimer.Every(System.TimeSpan)">
            <summary>
                Set the interval to send a replication command to a Solr server.
            </summary>
            <param name="interval">Interval this command is to be called.</param>
            <returns>Instance of ScheduledTimer for fluent configuration.</returns>
            <remarks>If no start time is set, the interval starts when the timer is started.</remarks>
        </member>
        <member name="M:KafkaNet.Common.IScheduledTimer.Do(System.Action)">
            <summary>
                Action to perform when the timer expires.
            </summary>
        </member>
        <member name="M:KafkaNet.Common.IScheduledTimer.DontWait">
            <summary>
            Sets the timer to execute and restart the timer without waiting for the Do method to finish.
            </summary>
            <returns></returns>
        </member>
        <member name="M:KafkaNet.Common.IScheduledTimer.Begin">
            <summary>
                Starts the timer
            </summary>
        </member>
        <member name="M:KafkaNet.Common.IScheduledTimer.End">
            <summary>
                Stop the timer.
            </summary>
        </member>
        <member name="T:KafkaNet.Common.ScheduledTimer">
            <summary>
            TODO there is a bug in this that sometimes calls the do function twice on startup
            Timer class which providers a fluent interface for scheduling task for threads to execute at some future point.
            
            Thanks goes to Jeff Vanzella for this nifty little fluent class for scheduling tasks.
            </summary>
        </member>
        <member name="P:KafkaNet.Common.ScheduledTimer.Status">
            <summary>
                Current running status of the timer.
            </summary>
        </member>
        <member name="M:KafkaNet.Common.ScheduledTimer.#ctor">
            <summary>
                Constructor.
            </summary>
        </member>
        <member name="P:KafkaNet.Common.ScheduledTimer.Enabled">
            <summary>
            Indicates if the timer is running.
            </summary>
        </member>
        <member name="M:KafkaNet.Common.ScheduledTimer.StartingAt(System.DateTime)">
            <summary>
                Set the time to start the first execution of the scheduled task.
            </summary>
            <param name="start">Start date and time for the replication timer.</param>
            <returns>Instance of IScheduledTimer for fluent configuration.</returns>
            <remarks>If no start time is set, the interval starts when the timer is started.</remarks>
        </member>
        <member name="M:KafkaNet.Common.ScheduledTimer.Dispose">
            <summary>
            Performs application-defined tasks associated with freeing, releasing, or resetting unmanaged resources.
            </summary>
        </member>
        <member name="M:KafkaNet.Common.ScheduledTimer.Every(System.TimeSpan)">
            <summary>
                Set the interval to wait between each execution of the task.
            </summary>
            <param name="interval">Interval to wait between execution of tasks.</param>
            <returns>Instance of IScheduledTimer for fluent configuration.</returns>
            <remarks>If no interval is set, the schedule will only execute once.</remarks>
        </member>
        <member name="M:KafkaNet.Common.ScheduledTimer.Do(System.Action)">
            <summary>
                Action to perform when the timer expires.
            </summary>
        </member>
        <member name="M:KafkaNet.Common.ScheduledTimer.DontWait">
            <summary>
            Sets the timer to execute and restart the timer without waiting for the Do method to finish.
            </summary>
            <remarks>
            Setting this will start the countdown timer to the next execution imediately 
            after the current execution is triggered.  If the execution action takes longer than
            the timer interval, the execution task will stack and run concurrently.
            </remarks>
        </member>
        <member name="M:KafkaNet.Common.ScheduledTimer.Begin">
            <summary>
                Starts the timer
            </summary>
        </member>
        <member name="M:KafkaNet.Common.ScheduledTimer.End">
            <summary>
                Stop the timer.
            </summary>
        </member>
        <member name="P:KafkaNet.Common.ScheduledTimer.TimerObject">
            <summary>
            Exposes the timer object for unit testing.
            </summary>
        </member>
        <member name="T:KafkaNet.Common.Crc32Provider">
            <summary>
            This code was originally from the copyrighted code listed above but was modified significantly
            as the original code was not thread safe and did not match was was required of this driver. This
            class now provides a static lib which will do the simple CRC calculation required by Kafka servers.
            </summary>
        </member>
        <member name="T:KafkaNet.Common.Extensions">
            <summary>
            Provides Big Endian conversion extensions to required types for the Kafka protocol.
            </summary>
        </member>
        <member name="M:KafkaNet.Common.Extensions.WithCancellation``1(System.Threading.Tasks.Task{``0},System.Threading.CancellationToken)">
            <summary>
            Execute an await task while monitoring a given cancellation token.  Use with non-cancelable async operations.
            </summary>
            <remarks>
            This extension method will only cancel the await and not the actual IO operation.  The status of the IO opperation will still
            need to be considered after the operation is cancelled.
            See <see cref="!:http://blogs.msdn.com/b/pfxteam/archive/2012/10/05/how-do-i-cancel-non-cancelable-async-operations.aspx"/>
            </remarks>
        </member>
        <member name="M:KafkaNet.Common.Extensions.WithCancellation(System.Threading.Tasks.Task,System.Threading.CancellationToken)">
            <summary>
            Execute an await task while monitoring a given cancellation token.  Use with non-cancelable async operations.
            </summary>
            <remarks>
            This extension method will only cancel the await and not the actual IO operation.  The status of the IO opperation will still
            need to be considered after the operation is cancelled.
            See <see cref="!:http://blogs.msdn.com/b/pfxteam/archive/2012/10/05/how-do-i-cancel-non-cancelable-async-operations.aspx"/>
            </remarks>
        </member>
        <member name="M:KafkaNet.Common.Extensions.WaitAsync(System.Threading.WaitHandle,System.TimeSpan)">
            <summary>
            Returns true if <see cref="T:System.Threading.WaitHandle"/> before timeout expires./>
            </summary>
            <param name="handle">The handle whose signal triggers the task to be completed.</param>
            <param name="timeout">The timespan to wait before returning false</param>
            <returns>The task returns true if the handle is signaled before the timeout has expired.</returns>
            <remarks>
            Original code from: http://blog.nerdbank.net/2011/07/c-await-for-waithandle.html
            There is a (brief) time delay between when the handle is signaled and when the task is marked as completed.
            </remarks>
        </member>
        <member name="M:KafkaNet.Common.Extensions.SafeWait(System.Threading.Tasks.Task,System.TimeSpan)">
            <summary>
            Mainly used for testing, allows waiting on a single task without throwing exceptions.
            </summary>
        </member>
        <member name="M:KafkaNet.Common.Extensions.Batch``1(System.Collections.Generic.IEnumerable{``0},System.Int32)">
            <summary>
            Splits a collection into given batch sizes and returns as an enumerable of batches.
            </summary>
        </member>
        <member name="M:KafkaNet.Common.Extensions.ExtractException(System.Threading.Tasks.Task)">
            <summary>
            Extracts a concrete exception out of a Continue with result.
            </summary>
        </member>
        <member name="T:KafkaNet.Statistics.StatisticsTracker">
            <summary>
            Statistics tracker uses circular buffers to capture a maximum set of current statistics.  
            </summary>
        </member>
        <member name="T:KafkaNet.ConsoleLog">
            <summary>
            This class simply logs all information out to the console. Usefull for 
            debug testing in console applications.
            </summary>
        </member>
        <member name="T:KafkaNet.IMetadataQueries">
            <summary>
            Contains common metadata query commands that are used by both a consumer and producer.
            </summary>
        </member>
        <member name="M:KafkaNet.IMetadataQueries.GetTopic(System.String)">
            <summary>
            Get metadata on the given topic.
            </summary>
            <param name="topic">The metadata on the requested topic.</param>
            <returns>Topic object containing the metadata on the requested topic.</returns>
        </member>
        <member name="M:KafkaNet.IMetadataQueries.GetTopicOffsetAsync(System.String,System.Int32,System.Int32)">
            <summary>
            Get offsets for each partition from a given topic.
            </summary>
            <param name="topic">Name of the topic to get offset information from.</param>
            <param name="maxOffsets"></param>
            <param name="time"></param>
            <returns></returns>
        </member>
        <member name="P:KafkaNet.IKafkaTcpSocket.Endpoint">
            <summary>
            The IP endpoint to the server.
            </summary>
        </member>
        <member name="M:KafkaNet.IKafkaTcpSocket.ReadAsync(System.Int32)">
            <summary>
            Read a certain byte array size return only when all bytes received.
            </summary>
            <param name="readSize">The size in bytes to receive from server.</param>
            <returns>Returns a byte[] array with the size of readSize.</returns>
        </member>
        <member name="M:KafkaNet.IKafkaTcpSocket.ReadAsync(System.Int32,System.Threading.CancellationToken)">
            <summary>
            Read a certain byte array size return only when all bytes received.
            </summary>
            <param name="readSize">The size in bytes to receive from server.</param>
            <param name="cancellationToken">A cancellation token which will cancel the request.</param>
            <returns>Returns a byte[] array with the size of readSize.</returns>
        </member>
        <member name="M:KafkaNet.IKafkaTcpSocket.WriteAsync(KafkaNet.KafkaDataPayload)">
            <summary>
            Convenience function to write full buffer data to the server.
            </summary>
            <param name="payload">The buffer data to send.</param>
            <returns>Returns Task handle to the write operation with size of written bytes.</returns>
        </member>
        <member name="M:KafkaNet.IKafkaTcpSocket.WriteAsync(KafkaNet.KafkaDataPayload,System.Threading.CancellationToken)">
            <summary>
            Write the buffer data to the server.
            </summary>
            <param name="payload">The buffer data to send.</param>
            <param name="cancellationToken">A cancellation token which will cancel the request.</param>
            <returns>Returns Task handle to the write operation ith size of written bytes..</returns>
        </member>
        <member name="T:KafkaNet.Consumer">
            <summary>
            Provides a basic consumer of one Topic across all partitions or over a given whitelist of partitions.
            
            TODO: provide automatic offset saving when the feature is available in 0.8.2
            https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol#AGuideToTheKafkaProtocol-OffsetCommit/FetchAPI
            </summary>
        </member>
        <member name="P:KafkaNet.Consumer.ConsumerTaskCount">
            <summary>
            Get the number of tasks created for consuming each partition.
            </summary>
        </member>
        <member name="M:KafkaNet.Consumer.Consume(System.Nullable{System.Threading.CancellationToken})">
            <summary>
            Returns a blocking enumerable of messages received from Kafka.
            </summary>
            <returns>Blocking enumberable of messages from Kafka.</returns>
        </member>
        <member name="M:KafkaNet.Consumer.SetOffsetPosition(KafkaNet.Protocol.OffsetPosition[])">
            <summary>
            Force reset the offset position for a specific partition to a specific offset value.
            </summary>
            <param name="positions">Collection of positions to reset to.</param>
        </member>
        <member name="M:KafkaNet.Consumer.GetOffsetPosition">
            <summary>
            Get the current running position (offset) for all consuming partition.
            </summary>
            <returns>List of positions for each consumed partitions.</returns>
            <remarks>Will only return data if the consumer is actively being consumed.</remarks>
        </member>
        <member name="P:KafkaNet.IKafkaConnection.Endpoint">
            <summary>
            The unique endpoint location of this connection.
            </summary>
        </member>
        <member name="P:KafkaNet.IKafkaConnection.ReadPolling">
            <summary>
            Value indicating the read polling thread is still active.
            </summary>
        </member>
        <member name="M:KafkaNet.IKafkaConnection.SendAsync(KafkaNet.KafkaDataPayload)">
            <summary>
            Send raw payload data up to the connected endpoint.
            </summary>
            <param name="payload">The raw data to send to the connected endpoint.</param>
            <returns>Task representing the future success or failure of query.</returns>
        </member>
        <member name="M:KafkaNet.IKafkaConnection.SendAsync``1(KafkaNet.IKafkaRequest{``0})">
            <summary>
            Send a specific IKafkaRequest to the connected endpoint.
            </summary>
            <typeparam name="T">The type of the KafkaResponse expected from the request being sent.</typeparam>
            <param name="request">The KafkaRequest to send to the connected endpoint.</param>
            <returns>Task representing the future responses from the sent request.</returns>
        </member>
        <member name="M:KafkaNet.IBrokerRouter.SelectBrokerRoute(System.String,System.Int32)">
            <summary>
            Select a broker for a specific topic and partitionId.
            </summary>
            <param name="topic">The topic name to select a broker for.</param>
            <param name="partitionId">The exact partition to select a broker for.</param>
            <returns>A broker route for the given partition of the given topic.</returns>
            <remarks>
            This function does not use any selector criteria.  If the given partitionId does not exist an exception will be thrown.
            </remarks>
            <exception cref="T:KafkaNet.Protocol.InvalidTopicMetadataException">Thrown if the returned metadata for the given topic is invalid or missing.</exception>
            <exception cref="T:KafkaNet.Protocol.InvalidPartitionException">Thrown if the give partitionId does not exist for the given topic.</exception>
            <exception cref="T:KafkaNet.Protocol.ServerUnreachableException">Thrown if none of the Default Brokers can be contacted.</exception>
        </member>
        <member name="M:KafkaNet.IBrokerRouter.SelectBrokerRoute(System.String,System.Byte[])">
            <summary>
            Select a broker for a given topic using the IPartitionSelector function.
            </summary>
            <param name="topic">The topic to retreive a broker route for.</param>
            <param name="key">The key used by the IPartitionSelector to collate to a consistent partition. Null value means key will be ignored in selection process.</param>
            <returns>A broker route for the given topic.</returns>
            <exception cref="T:KafkaNet.Protocol.InvalidTopicMetadataException">Thrown if the returned metadata for the given topic is invalid or missing.</exception>
            <exception cref="T:KafkaNet.Protocol.ServerUnreachableException">Thrown if none of the Default Brokers can be contacted.</exception>
        </member>
        <member name="M:KafkaNet.IBrokerRouter.GetTopicMetadata(System.String[])">
            <summary>
            Returns Topic metadata for each topic requested. 
            </summary>
            <param name="topics">Collection of topids to request metadata for.</param>
            <returns>List of Topics as provided by Kafka.</returns>
            <remarks>The topic metadata will by default check the cache first and then request metadata from the server if it does not exist in cache.</remarks>
        </member>
        <member name="M:KafkaNet.IBrokerRouter.RefreshTopicMetadata(System.String[])">
            <summary>
            Force a call to the kafka servers to refresh metadata for the given topics.
            </summary>
            <param name="topics">List of topics to update metadata for.</param>
            <remarks>
            This method will initiate a call to the kafka servers and retrieve metadata for all given topics, updating the broke cache in the process.
            </remarks>
        </member>
        <member name="T:KafkaNet.MetadataQueries">
            <summary>
            This class provides a set of common queries that are useful for both the Consumer and Producer classes.  
            </summary>
        </member>
        <member name="M:KafkaNet.MetadataQueries.GetTopicOffsetAsync(System.String,System.Int32,System.Int32)">
            <summary>
            Get offsets for each partition from a given topic.
            </summary>
            <param name="topic">Name of the topic to get offset information from.</param>
            <param name="maxOffsets"></param>
            <param name="time"></param>
            <returns></returns>
        </member>
        <member name="M:KafkaNet.MetadataQueries.GetTopic(System.String)">
            <summary>
            Get metadata on the given topic.
            </summary>
            <param name="topic">The metadata on the requested topic.</param>
            <returns>Topic object containing the metadata on the requested topic.</returns>
        </member>
        <member name="P:KafkaNet.Model.ConsumerOptions.Topic">
            <summary>
            The topic to consume messages from.
            </summary>
        </member>
        <member name="P:KafkaNet.Model.ConsumerOptions.PartitionWhitelist">
            <summary>
            Whitelist of partitions to consume from.  Empty list indicates all partitions.
            </summary>
        </member>
        <member name="P:KafkaNet.Model.ConsumerOptions.Log">
            <summary>
            Log object to record operational messages.
            </summary>
        </member>
        <member name="P:KafkaNet.Model.ConsumerOptions.Router">
            <summary>
            The broker router used to provide connection to each partition server.
            </summary>
        </member>
        <member name="P:KafkaNet.Model.ConsumerOptions.TopicPartitionQueryTimeMs">
            <summary>
            The time in milliseconds between queries to look for any new partitions being created.
            </summary>
        </member>
        <member name="P:KafkaNet.Model.ConsumerOptions.ConsumerBufferSize">
            <summary>
            The size of the internal buffer queue which stores messages from Kafka.
            </summary>
        </member>
        <member name="P:KafkaNet.Model.ConsumerOptions.BackoffInterval">
            <summary>
            The interval for the consumer to sleep before try fetch next message if previous fetch received no message. 
            </summary>
        </member>
        <member name="P:KafkaNet.Model.ConsumerOptions.MaxWaitTimeForMinimumBytes">
            <summary>
            The max wait time is the maximum amount of time in milliseconds to block waiting if insufficient data is available at the time the request is issued.
            </summary>
        </member>
        <member name="P:KafkaNet.Model.ConsumerOptions.MinimumBytes">
            <summary>
            This is the minimum number of bytes of messages that must be available to give a response. If the client sets this to 0 the server will always respond immediately, 
            however if there is no new data since their last request they will just get back empty message sets. If this is set to 1, the server will respond as soon as at least 
            one partition has at least 1 byte of data or the specified timeout occurs. By setting higher values in combination with the timeout the consumer can tune for throughput 
            and trade a little additional latency for reading only large chunks of data (e.g. setting MaxWaitTime to 100 ms and setting MinBytes to 64k would allow the server to wait 
            up to 100ms to try to accumulate 64k of data before responding).
            </summary>
        </member>
        <member name="P:KafkaNet.Model.ConsumerOptions.FetchBufferMultiplier">
            <summary>
            In the event of a buffer under run, this multiplier will allow padding the new buffer size.
            </summary>
        </member>
        <member name="P:KafkaNet.Model.KafkaOptions.KafkaServerUri">
            <summary>
            List of Uri connections to kafka servers.  The are used to query for metadata from Kafka.  More than one is recommended.
            </summary>
        </member>
        <member name="P:KafkaNet.Model.KafkaOptions.KafkaServerEndpoints">
            <summary>
            Safely attempts to resolve endpoints from the KafkaServerUri, ignoreing all resolvable ones.
            </summary>
        </member>
        <member name="P:KafkaNet.Model.KafkaOptions.KafkaConnectionFactory">
            <summary>
            Provides a factory for creating new kafka connections.
            </summary>
        </member>
        <member name="P:KafkaNet.Model.KafkaOptions.PartitionSelector">
            <summary>
            Selector function for routing messages to partitions. Default is key/hash and round robin.
            </summary>
        </member>
        <member name="P:KafkaNet.Model.KafkaOptions.ResponseTimeoutMs">
            <summary>
            Timeout length in milliseconds waiting for a response from kafka.
            </summary>
        </member>
        <member name="P:KafkaNet.Model.KafkaOptions.Log">
            <summary>
            Log object to record operational messages.
            </summary>
        </member>
        <member name="P:KafkaNet.Model.KafkaOptions.MaximumReconnectionTimeout">
            <summary>
            The maximum time to wait when backing off on reconnection attempts.
            </summary>
        </member>
        <member name="M:KafkaNet.IKafkaLog.DebugFormat(System.String,System.Object[])">
            <summary>
            Record debug information using the String.Format syntax.
            </summary>
            <param name="format">Format string template. e.g. "Exception = {0}"</param>
            <param name="args">Arguments which will fill the template string in order of apperance.</param>
        </member>
        <member name="M:KafkaNet.IKafkaLog.InfoFormat(System.String,System.Object[])">
            <summary>
            Record info information using the String.Format syntax.
            </summary>
            <param name="format">Format string template. e.g. "Exception = {0}"</param>
            <param name="args">Arguments which will fill the template string in order of apperance.</param>
        </member>
        <member name="M:KafkaNet.IKafkaLog.WarnFormat(System.String,System.Object[])">
            <summary>
            Record warning information using the String.Format syntax.
            </summary>
            <param name="format">Format string template. e.g. "Exception = {0}"</param>
            <param name="args">Arguments which will fill the template string in order of apperance.</param>
        </member>
        <member name="M:KafkaNet.IKafkaLog.ErrorFormat(System.String,System.Object[])">
            <summary>
            Record error information using the String.Format syntax.
            </summary>
            <param name="format">Format string template. e.g. "Exception = {0}"</param>
            <param name="args">Arguments which will fill the template string in order of apperance.</param>
        </member>
        <member name="M:KafkaNet.IKafkaLog.FatalFormat(System.String,System.Object[])">
            <summary>
            Record fatal information using the String.Format syntax.
            </summary>
            <param name="format">Format string template. e.g. "Exception = {0}"</param>
            <param name="args">Arguments which will fill the template string in order of apperance.</param>
        </member>
        <member name="M:KafkaNet.IPartitionSelector.Select(KafkaNet.Protocol.Topic,System.Byte[])">
            <summary>
            Select the appropriate partition post a message based on topic and key data.
            </summary>
            <param name="topic">The topic at which the message will be sent.</param>
            <param name="key">The data used to consistently route a message to a particular partition.  Value can be null.</param>
            <returns>The partition to send the message to.</returns>
        </member>
        <member name="T:KafkaNet.BrokerRouter">
            <summary>
            This class provides an abstraction from querying multiple Kafka servers for Metadata details and caching this data.
            
            All metadata queries are cached lazily.  If metadata from a topic does not exist in cache it will be queried for using
            the default brokers provided in the constructor.  Each Uri will be queried to get metadata information in turn until a
            response is received.  It is recommended therefore to provide more than one Kafka Uri as this API will be able to to get
            metadata information even if one of the Kafka servers goes down.
            
            The metadata will stay in cache until an error condition is received indicating the metadata is out of data.  This error 
            can be in the form of a socket disconnect or an error code from a response indicating a broker no longer hosts a partition.
            </summary>
        </member>
        <member name="M:KafkaNet.BrokerRouter.SelectBrokerRoute(System.String,System.Int32)">
            <summary>
            Select a broker for a specific topic and partitionId.
            </summary>
            <param name="topic">The topic name to select a broker for.</param>
            <param name="partitionId">The exact partition to select a broker for.</param>
            <returns>A broker route for the given partition of the given topic.</returns>
            <remarks>
            This function does not use any selector criteria.  If the given partitionId does not exist an exception will be thrown.
            </remarks>
            <exception cref="T:KafkaNet.Protocol.InvalidTopicMetadataException">Thrown if the returned metadata for the given topic is invalid or missing.</exception>
            <exception cref="T:KafkaNet.Protocol.InvalidPartitionException">Thrown if the give partitionId does not exist for the given topic.</exception>
            <exception cref="T:KafkaNet.Protocol.ServerUnreachableException">Thrown if none of the Default Brokers can be contacted.</exception>
        </member>
        <member name="M:KafkaNet.BrokerRouter.SelectBrokerRoute(System.String,System.Byte[])">
            <summary>
            Select a broker for a given topic using the IPartitionSelector function.
            </summary>
            <param name="topic">The topic to retreive a broker route for.</param>
            <param name="key">The key used by the IPartitionSelector to collate to a consistent partition. Null value means key will be ignored in selection process.</param>
            <returns>A broker route for the given topic.</returns>
            <exception cref="T:KafkaNet.Protocol.InvalidTopicMetadataException">Thrown if the returned metadata for the given topic is invalid or missing.</exception>
            <exception cref="T:KafkaNet.Protocol.ServerUnreachableException">Thrown if none of the Default Brokers can be contacted.</exception>
        </member>
        <member name="M:KafkaNet.BrokerRouter.GetTopicMetadata(System.String[])">
            <summary>
            Returns Topic metadata for each topic requested. 
            </summary>
            <param name="topics">Collection of topics to request metadata for.</param>
            <returns>List of Topics as provided by Kafka.</returns>
            <remarks>
            The topic metadata will by default check the cache first and then if it does not exist it will then
            request metadata from the server.  To force querying the metadata from the server use <see cref="M:KafkaNet.BrokerRouter.RefreshTopicMetadata(System.String[])"/>
            </remarks>
        </member>
        <member name="M:KafkaNet.BrokerRouter.RefreshTopicMetadata(System.String[])">
            <summary>
            Force a call to the kafka servers to refresh metadata for the given topics.
            </summary>
            <param name="topics">List of topics to update metadata for.</param>
            <remarks>
            This method will ignore the cache and initiate a call to the kafka servers for all given topics, updating the cache with the resulting metadata.
            Only call this method to force a metadata update.  For all other queries use <see cref="M:KafkaNet.BrokerRouter.GetTopicMetadata(System.String[])"/> which uses cached values.
            </remarks>
        </member>
        <member name="T:KafkaNet.KafkaMetadataProvider">
            <summary>
            This provider blocks while it attempts to get the MetaData configuration of the Kafka servers.  If any retry errors occurs it will
            continue to block the downstream call and then repeatedly query kafka until the retry errors subside.  This repeat call happens in 
            a backoff manner, which each subsequent call waiting longer before a requery.
            
            Error Codes:
            LeaderNotAvailable = 5
            NotLeaderForPartition = 6
            ConsumerCoordinatorNotAvailableCode = 15
            BrokerId = -1
            
            Documentation:
            https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol#AGuideToTheKafkaProtocol-MetadataResponse
            </summary>
        </member>
        <member name="M:KafkaNet.KafkaMetadataProvider.Get(KafkaNet.IKafkaConnection[],System.Collections.Generic.IEnumerable{System.String})">
            <summary>
            Given a collection of server connections, query for the topic metadata.
            </summary>
            <param name="connections">The server connections to query.  Will cycle through the collection, starting at zero until a response is received.</param>
            <param name="topics">The collection of topics to get metadata for.</param>
            <returns>MetadataResponse validated to be complete.</returns>
        </member>
        <member name="T:KafkaNet.Protocol.ConsumerMetadataRequest">
            <summary>
            https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol#AGuideToTheKafkaProtocol-OffsetFetchRequest
            The offsets for a given consumer group is maintained by a specific broker called the offset coordinator. i.e., a consumer needs 
            to issue its offset commit and fetch requests to this specific broker. It can discover the current offset coordinator by issuing a consumer metadata request.
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.ConsumerMetadataResponse.Error">
            <summary>
            Error code of exception that occured during the request.  Zero if no error.
            </summary>
        </member>
        <member name="T:KafkaNet.Protocol.OffsetFetchRequest">
            <summary>
            Class that represents both the request and the response from a kafka server of requesting a stored offset value
            for a given consumer group.  Essentially this part of the api allows a user to save/load a given offset position
            under any abritrary name.
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.OffsetFetch.Topic">
            <summary>
            The topic the offset came from.
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.OffsetFetch.PartitionId">
            <summary>
            The partition the offset came from.
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.OffsetFetchResponse.Topic">
            <summary>
            The name of the topic this response entry is for.
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.OffsetFetchResponse.PartitionId">
            <summary>
            The id of the partition this response is for.
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.OffsetFetchResponse.Offset">
            <summary>
            The offset position saved to the server.
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.OffsetFetchResponse.MetaData">
            <summary>
            Any arbitrary metadata stored during a CommitRequest.
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.OffsetFetchResponse.Error">
            <summary>
            Error code of exception that occured during the request.  Zero if no error.
            </summary>
        </member>
        <member name="T:KafkaNet.Protocol.Compression">
            <summary>
            Extension methods which allow compression of byte arrays
            </summary>
        </member>
        <member name="T:KafkaNet.Protocol.ApiKeyRequestType">
            <summary>
            Enumeration of numeric codes that the ApiKey in the request can take for each request types. 
            </summary>
        </member>
        <member name="T:KafkaNet.Protocol.ErrorResponseCode">
            <summary>
            Enumeration of error codes that might be returned from a Kafka server
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.ErrorResponseCode.NoError">
            <summary>
            No error--it worked!
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.ErrorResponseCode.Unknown">
            <summary>
            An unexpected server error
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.ErrorResponseCode.OffsetOutOfRange">
            <summary>
            The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.ErrorResponseCode.InvalidMessage">
            <summary>
            This indicates that a message contents does not match its CRC
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.ErrorResponseCode.UnknownTopicOrPartition">
            <summary>
            This request is for a topic or partition that does not exist on this broker.
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.ErrorResponseCode.InvalidMessageSize">
            <summary>
            The message has a negative size
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.ErrorResponseCode.LeaderNotAvailable">
            <summary>
            This error is thrown if we are in the middle of a leadership election and there is currently no leader for this partition and hence it is unavailable for writes.
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.ErrorResponseCode.NotLeaderForPartition">
            <summary>
            This error is thrown if the client attempts to send messages to a replica that is not the leader for some partition. It indicates that the clients metadata is out of date.
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.ErrorResponseCode.RequestTimedOut">
            <summary>
            This error is thrown if the request exceeds the user-specified time limit in the request.
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.ErrorResponseCode.BrokerNotAvailable">
            <summary>
            This is not a client facing error and is used only internally by intra-cluster broker communication.
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.ErrorResponseCode.ReplicaNotAvailable">
            <summary>
            If replica is expected on a broker, but is not.
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.ErrorResponseCode.MessageSizeTooLarge">
            <summary>
            The server has a configurable maximum message size to avoid unbounded memory allocation. This error is thrown if the client attempt to produce a message larger than this maximum.
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.ErrorResponseCode.StaleControllerEpochCode">
            <summary>
            Internal error code for broker-to-broker communication.
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.ErrorResponseCode.OffsetMetadataTooLargeCode">
            <summary>
            If you specify a string larger than configured maximum for offset metadata
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.ErrorResponseCode.OffsetsLoadInProgressCode">
            <summary>
            The broker returns this error code for an offset fetch request if it is still loading offsets (after a leader change for that offsets topic partition).
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.ErrorResponseCode.ConsumerCoordinatorNotAvailableCode">
            <summary>
            The broker returns this error code for consumer metadata requests or offset commit requests if the offsets topic has not yet been created.
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.ErrorResponseCode.NotCoordinatorForConsumerCode">
            <summary>
            The broker returns this error code if it receives an offset fetch or commit request for a consumer group that it is not a coordinator for.
            </summary>
        </member>
        <member name="T:KafkaNet.Protocol.ProtocolConstants">
            <summary>
            Protocol specific constants
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.ProtocolConstants.AttributeCodeMask">
            <summary>
             The lowest 2 bits contain the compression codec used for the message. The other bits should be set to 0.
            </summary>
        </member>
        <member name="T:KafkaNet.Protocol.MessageCodec">
            <summary>
            Enumeration which specifies the compression type of messages
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.BaseRequest.ReplicaId">
            <summary>
            From Documentation: 
            The replica id indicates the node id of the replica initiating this request. Normal client consumers should always specify this as -1 as they have no node id. 
            Other brokers set this to be their own node id. The value -2 is accepted to allow a non-broker to issue fetch requests as if it were a replica broker for debugging purposes.
            
            Kafka Protocol implementation:
            https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.BaseRequest.ClientId">
            <summary>
            Descriptive name of the source of the messages sent to kafka
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.BaseRequest.CorrelationId">
            <summary>
            Value supplied will be passed back in the response by the server unmodified. 
            It is useful for matching request and response between the client and server. 
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.BaseRequest.ExpectResponse">
            <summary>
            Flag which tells the broker call to expect a response for this request.
            </summary>
        </member>
        <member name="M:KafkaNet.Protocol.BaseRequest.EncodeHeader``1(KafkaNet.IKafkaRequest{``0})">
            <summary>
            Encode the common head for kafka request.
            </summary>
            <returns>KafkaMessagePacker with header populated</returns>
            <remarks>Format: (hhihs) </remarks>
        </member>
        <member name="P:KafkaNet.Protocol.FetchRequest.ApiKey">
            <summary>
            Indicates the type of kafka encoding this request is
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.FetchRequest.MaxWaitTime">
            <summary>
            The max wait time is the maximum amount of time in milliseconds to block waiting if insufficient data is available at the time the request is issued.
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.FetchRequest.MinBytes">
            <summary>
            This is the minimum number of bytes of messages that must be available to give a response. 
            If the client sets this to 0 the server will always respond immediately, however if there is no new data since their last request they will just get back empty message sets. 
            If this is set to 1, the server will respond as soon as at least one partition has at least 1 byte of data or the specified timeout occurs. 
            By setting higher values in combination with the timeout the consumer can tune for throughput and trade a little additional latency for reading only large chunks of data 
            (e.g. setting MaxWaitTime to 100 ms and setting MinBytes to 64k would allow the server to wait up to 100ms to try to accumulate 64k of data before responding).
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.Fetch.Topic">
            <summary>
            The name of the topic.
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.Fetch.PartitionId">
            <summary>
            The id of the partition the fetch is for.
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.Fetch.Offset">
            <summary>
            The offset to begin this fetch from.
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.Fetch.MaxBytes">
            <summary>
            The maximum bytes to include in the message set for this partition. This helps bound the size of the response.
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.FetchResponse.Topic">
            <summary>
            The name of the topic this response entry is for.
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.FetchResponse.PartitionId">
            <summary>
            The id of the partition this response is for.
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.FetchResponse.Error">
            <summary>
            Error code of exception that occured during the request.  Zero if no error.
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.FetchResponse.HighWaterMark">
            <summary>
            The offset at the end of the log for this partition. This can be used by the client to determine how many messages behind the end of the log they are.
            </summary>
        </member>
        <member name="T:KafkaNet.Protocol.Payload">
            <summary>
            Buffer represents a collection of messages to be posted to a specified Topic on specified Partition.
            </summary>
        </member>
        <member name="T:KafkaNet.Protocol.Message">
            <summary>
            Message represents the data from a single event occurance.
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.Message.Meta">
            <summary>
            Metadata on source offset and partition location for this message.
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.Message.MagicNumber">
            <summary>
            This is a version id used to allow backwards compatible evolution of the message binary format.  Reserved for future use.  
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.Message.Attribute">
            <summary>
            Attribute value outside message body used for added codec/compression info.
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.Message.Key">
            <summary>
            Key value used for routing message to partitions.
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.Message.Value">
            <summary>
            The message body contents.  Can contain compress message set.
            </summary>
        </member>
        <member name="M:KafkaNet.Protocol.Message.#ctor">
            <summary>
            Construct an empty message.
            </summary>
        </member>
        <member name="M:KafkaNet.Protocol.Message.#ctor(System.String,System.String)">
            <summary>
            Convenience constructor will encode both the key and message to byte streams.
            Most of the time a message will be string based.
            </summary>
            <param name="key">The key value for the message.  Can be null.</param>
            <param name="value">The main content data of this message.</param>
        </member>
        <member name="M:KafkaNet.Protocol.Message.EncodeMessageSet(System.Collections.Generic.IEnumerable{KafkaNet.Protocol.Message})">
            <summary>
            Encodes a collection of messages into one byte[].  Encoded in order of list.
            </summary>
            <param name="messages">The collection of messages to encode together.</param>
            <returns>Encoded byte[] representing the collection of messages.</returns>
        </member>
        <member name="M:KafkaNet.Protocol.Message.DecodeMessageSet(System.Byte[])">
            <summary>
            Decode a byte[] that represents a collection of messages.
            </summary>
            <param name="messageSet">The byte[] encode as a message set from kafka.</param>
            <returns>Enumerable representing stream of messages decoded from byte[]</returns>
        </member>
        <member name="M:KafkaNet.Protocol.Message.EncodeMessage(KafkaNet.Protocol.Message)">
            <summary>
            Encodes a message object to byte[]
            </summary>
            <param name="message">Message data to encode.</param>
            <returns>Encoded byte[] representation of the message object.</returns>
            <remarks>
            Format:
            Crc (Int32), MagicByte (Byte), Attribute (Byte), Key (Byte[]), Value (Byte[])
            </remarks>
        </member>
        <member name="M:KafkaNet.Protocol.Message.DecodeMessage(System.Int64,System.Byte[])">
            <summary>
            Decode messages from a payload and assign it a given kafka offset.
            </summary>
            <param name="offset">The offset represting the log entry from kafka of this message.</param>
            <param name="payload">The byte[] encode as a message from kafka.</param>
            <returns>Enumerable representing stream of messages decoded from byte[].</returns>
            <remarks>The return type is an Enumerable as the message could be a compressed message set.</remarks>
        </member>
        <member name="T:KafkaNet.Protocol.MessageMetadata">
            <summary>
            Provides metadata about the message received from the FetchResponse
            </summary>
            <remarks>
            The purpose of this metadata is to allow client applications to track their own offset information about messages received from Kafka.
            <see cref="!:http://kafka.apache.org/documentation.html#semantics"/>
            </remarks>
        </member>
        <member name="P:KafkaNet.Protocol.MessageMetadata.Offset">
            <summary>
            The log offset of this message as stored by the Kafka server.
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.MessageMetadata.PartitionId">
            <summary>
            The partition id this offset is from.
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.Partition.ErrorCode">
            <summary>
            Error code. 0 indicates no error occured.
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.Partition.PartitionId">
            <summary>
            The Id of the partition that this metadata describes.
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.Partition.LeaderId">
            <summary>
            The node id for the kafka broker currently acting as leader for this partition. If no leader exists because we are in the middle of a leader election this id will be -1.
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.Partition.Replicas">
            <summary>
            The set of alive nodes that currently acts as slaves for the leader for this partition.
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.Partition.Isrs">
            <summary>
            The set subset of the replicas that are "caught up" to the leader
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.MetadataRequest.ApiKey">
            <summary>
            Indicates the type of kafka encoding this request is
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.MetadataRequest.Topics">
            <summary>
            The list of topics to get metadata for.
            </summary>
        </member>
        <member name="M:KafkaNet.Protocol.MetadataRequest.EncodeMetadataRequest(KafkaNet.Protocol.MetadataRequest)">
            <summary>
            Encode a request for metadata about topic and broker information.
            </summary>
            <param name="request">The MetaDataRequest to encode.</param>
            <returns>Encoded byte[] representing the request.</returns>
            <remarks>Format: (PayloadSize), Header, ix(hs)</remarks>
        </member>
        <member name="M:KafkaNet.Protocol.MetadataRequest.DecodeMetadataResponse(System.Byte[])">
            <summary>
            Decode the metadata response from kafka server.
            </summary>
            <param name="data"></param>
            <returns></returns>
        </member>
        <member name="T:KafkaNet.Protocol.OffsetCommitRequest">
            <summary>
            Class that represents the api call to commit a specific set of offsets for a given topic.  The offset is saved under the 
            arbitrary ConsumerGroup name provided by the call.
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.OffsetCommit.Topic">
            <summary>
            The topic the offset came from.
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.OffsetCommit.PartitionId">
            <summary>
            The partition the offset came from.
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.OffsetCommit.Offset">
            <summary>
            The offset number to commit as completed.
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.OffsetCommit.TimeStamp">
            <summary>
            If the time stamp field is set to -1, then the broker sets the time stamp to the receive time before committing the offset.
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.OffsetCommit.Metadata">
            <summary>
            Descriptive metadata about this commit.
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.OffsetCommitResponse.Topic">
            <summary>
            The name of the topic this response entry is for.
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.OffsetCommitResponse.PartitionId">
            <summary>
            The id of the partition this response is for.
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.OffsetCommitResponse.Error">
            <summary>
            Error code of exception that occured during the request.  Zero if no error.
            </summary>
        </member>
        <member name="T:KafkaNet.Protocol.OffsetRequest">
            <summary>
            A funky Protocol for requesting the starting offset of each segment for the requested partition 
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.Offset.Time">
            <summary>
            Used to ask for all messages before a certain time (ms). There are two special values. 
            Specify -1 to receive the latest offsets and -2 to receive the earliest available offset. 
            Note that because offsets are pulled in descending order, asking for the earliest offset will always return you a single element.
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.ProduceRequest.ExpectResponse">
            <summary>
            Provide a hint to the broker call not to expect a response for requests without Acks.
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.ProduceRequest.ApiKey">
            <summary>
            Indicates the type of kafka encoding this request is.
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.ProduceRequest.TimeoutMS">
            <summary>
            Time kafka will wait for requested ack level before returning.
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.ProduceRequest.Acks">
            <summary>
            Level of ack required by kafka.  0 immediate, 1 written to leader, 2+ replicas synced, -1 all replicas
            </summary>
        </member>
        <member name="F:KafkaNet.Protocol.ProduceRequest.Payload">
            <summary>
            Collection of payloads to post to kafka
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.ProduceResponse.Topic">
            <summary>
            The topic the offset came from.
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.ProduceResponse.PartitionId">
            <summary>
            The partition the offset came from.
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.ProduceResponse.Error">
            <summary>
            Error response code.  0 is success.
            </summary>
        </member>
        <member name="P:KafkaNet.Protocol.ProduceResponse.Offset">
            <summary>
            The offset number to commit as completed.
            </summary>
        </member>
        <member name="M:KafkaNet.IKafkaConnectionFactory.Create(KafkaNet.Model.KafkaEndpoint,System.TimeSpan,KafkaNet.IKafkaLog,System.Nullable{System.TimeSpan})">
            <summary>
            Create a new KafkaConnection.
            </summary>
            <param name="endpoint">The specific KafkaEndpoint of the server to connect to.</param>
            <param name="responseTimeoutMs">The amount of time to wait for a message response to be received after sending a message to Kafka</param>
            <param name="log">Logging interface used to record any log messages created by the connection.</param>
            <param name="maximumReconnectionTimeout">The maximum time to wait when backing off on reconnection attempts.</param>
            <returns>IKafkaConnection initialized to connecto to the given endpoint.</returns>
        </member>
        <member name="M:KafkaNet.IKafkaConnectionFactory.Resolve(System.Uri,KafkaNet.IKafkaLog)">
            <summary>
            Resolves a generic Uri into a uniquely identifiable KafkaEndpoint.
            </summary>
            <param name="kafkaAddress">The address to the kafka server to resolve.</param>
            <param name="log">Logging interface used to record any log messages created by the Resolving process.</param>
            <returns>KafkaEndpoint with resolved IP and Address.</returns>
        </member>
        <member name="T:KafkaNet.Producer">
            <summary>
            Provides a simplified high level API for producing messages on a topic.
            </summary>
        </member>
        <member name="P:KafkaNet.Producer.BufferCount">
            <summary>
            Get the number of messages sitting in the buffer waiting to be sent. 
            </summary>
        </member>
        <member name="P:KafkaNet.Producer.InFlightMessageCount">
            <summary>
            Get the number of messages staged for Async upload.
            </summary>
        </member>
        <member name="P:KafkaNet.Producer.AsyncCount">
            <summary>
            Get the number of active async threads sending messages.
            </summary>
        </member>
        <member name="P:KafkaNet.Producer.BatchSize">
            <summary>
            The number of messages to wait for before sending to kafka.  Will wait <see cref="P:KafkaNet.Producer.BatchDelayTime"/> before sending whats received.
            </summary>
        </member>
        <member name="P:KafkaNet.Producer.BatchDelayTime">
            <summary>
            The time to wait for a batch size of <see cref="P:KafkaNet.Producer.BatchSize"/> before sending messages to kafka.
            </summary>
        </member>
        <member name="P:KafkaNet.Producer.BrokerRouter">
            <summary>
            The broker router this producer uses to route messages.
            </summary>
        </member>
        <member name="M:KafkaNet.Producer.#ctor(KafkaNet.IBrokerRouter,System.Int32,System.Int32)">
            <summary>
            Construct a Producer class.
            </summary>
            <param name="brokerRouter">The router used to direct produced messages to the correct partition.</param>
            <param name="maximumAsyncRequests">The maximum async calls allowed before blocking new requests.  -1 indicates unlimited.</param>
            <param name="maximumMessageBuffer">The maximum amount of messages to buffer if the async calls are blocking from sending.</param>
            <remarks>
            The maximumAsyncRequests parameter provides a mechanism for minimizing the amount of async requests in flight at any one time
            by blocking the caller requesting the async call.  This affectively puts an upper limit on the amount of times a caller can 
            call SendMessageAsync before the caller is blocked.
            
            The MaximumMessageBuffer parameter provides a way to limit the max amount of memory the driver uses should the send pipeline get
            overwhelmed and the buffer starts to fill up.  This is an inaccurate limiting memory use as the amount of memory actually used is 
            dependant on the general message size being buffered.
            
            A message will start its timeout countdown as soon as it is added to the producer async queue.  If there are a large number of 
            messages sitting in the async queue then a message may spend its entire timeout cycle waiting in this queue and never getting
            attempted to send to Kafka before a timeout exception is thrown.
            </remarks>
        </member>
        <member name="M:KafkaNet.Producer.SendMessageAsync(System.String,System.Collections.Generic.IEnumerable{KafkaNet.Protocol.Message},System.Int16,System.Nullable{System.TimeSpan},KafkaNet.Protocol.MessageCodec)">
            <summary>
            Send an enumerable of message objects to a given topic.
            </summary>
            <param name="topic">The name of the kafka topic to send the messages to.</param>
            <param name="messages">The enumerable of messages that will be sent to the given topic.</param>
            <param name="acks">The required level of acknowlegment from the kafka server.  0=none, 1=writen to leader, 2+=writen to replicas, -1=writen to all replicas.</param>
            <param name="timeout">Interal kafka timeout to wait for the requested level of ack to occur before returning. Defaults to 1000ms.</param>
            <param name="codec">The codec to apply to the message collection.  Defaults to none.</param>
            <returns>List of ProduceResponses from each partition sent to or empty list if acks = 0.</returns>
        </member>
        <member name="M:KafkaNet.Producer.GetTopic(System.String)">
            <summary>
            Get the metadata about a given topic.
            </summary>
            <param name="topic">The name of the topic to get metadata for.</param>
            <returns>Topic with metadata information.</returns>
        </member>
        <member name="M:KafkaNet.Producer.Stop(System.Boolean,System.Nullable{System.TimeSpan})">
            <summary>
            Stops the producer from accepting new messages, and optionally waits for in-flight messages to be sent before returning.
            </summary>
            <param name="waitForRequestsToComplete">True to wait for in-flight requests to complete, false otherwise.</param>
            <param name="maxWait">Maximum time to wait for in-flight requests to complete. Has no effect if <c>waitForRequestsToComplete</c> is false</param>
        </member>
        <member name="T:KafkaNet.KafkaConnection">
            <summary>
            KafkaConnection represents the lowest level TCP stream connection to a Kafka broker. 
            The Send and Receive are separated into two disconnected paths and must be combine outside
            this class by the correlation ID contained within the returned message.
            
            The SendAsync function will return a Task and complete once the data has been sent to the outbound stream.
            The Read response is handled by a single thread polling the stream for data and firing an OnResponseReceived
            event when a response is received.
            </summary>
        </member>
        <member name="M:KafkaNet.KafkaConnection.#ctor(KafkaNet.IKafkaTcpSocket,System.Nullable{System.TimeSpan},KafkaNet.IKafkaLog)">
            <summary>
            Initializes a new instance of the KafkaConnection class.
            </summary>
            <param name="log">Logging interface used to record any log messages created by the connection.</param>
            <param name="client">The kafka socket initialized to the kafka server.</param>
            <param name="responseTimeoutMs">The amount of time to wait for a message response to be received after sending message to Kafka.  Defaults to 30s.</param>
        </member>
        <member name="P:KafkaNet.KafkaConnection.ReadPolling">
            <summary>
            Indicates a thread is polling the stream for data to read.
            </summary>
        </member>
        <member name="P:KafkaNet.KafkaConnection.Endpoint">
            <summary>
            Provides the unique ip/port endpoint for this connection
            </summary>
        </member>
        <member name="M:KafkaNet.KafkaConnection.SendAsync(KafkaNet.KafkaDataPayload)">
            <summary>
            Send raw byte[] payload to the kafka server with a task indicating upload is complete.
            </summary>
            <param name="payload">kafka protocol formatted byte[] payload</param>
            <returns>Task which signals the completion of the upload of data to the server.</returns>
        </member>
        <member name="M:KafkaNet.KafkaConnection.SendAsync(KafkaNet.KafkaDataPayload,System.Threading.CancellationToken)">
            <summary>
            Send raw byte[] payload to the kafka server with a task indicating upload is complete.
            </summary>
            <param name="payload">kafka protocol formatted byte[] payload</param>
            <param name="token">Cancellation token used to cancel the transfer.</param>
            <returns>Task which signals the completion of the upload of data to the server.</returns>
        </member>
        <member name="M:KafkaNet.KafkaConnection.SendAsync``1(KafkaNet.IKafkaRequest{``0})">
            <summary>
            Send kafka payload to server and receive a task event when response is received.
            </summary>
            <typeparam name="T">A Kafka response object return by decode function.</typeparam>
            <param name="request">The IKafkaRequest to send to the kafka servers.</param>
            <returns></returns>
        </member>
        <member name="T:KafkaNet.IKafkaRequest`1">
            <summary>
            KafkaRequest represents a Kafka request messages as an object which can Encode itself into the appropriate 
            binary request and Decode any responses to that request.
            </summary>
            <typeparam name="T">The type of the KafkaResponse expected back from the request.</typeparam>
        </member>
        <member name="P:KafkaNet.IKafkaRequest`1.ExpectResponse">
            <summary>
            Indicates this request should wait for a response from the broker
            </summary>
        </member>
        <member name="P:KafkaNet.IKafkaRequest`1.ClientId">
            <summary>
            Descriptive name used to identify the source of this request. 
            </summary>
        </member>
        <member name="P:KafkaNet.IKafkaRequest`1.CorrelationId">
            <summary>
            Id which will be echoed back by Kafka to correlate responses to this request.  Usually automatically assigned by driver.
            </summary>
        </member>
        <member name="P:KafkaNet.IKafkaRequest`1.ApiKey">
            <summary>
            Enum identifying the specific type of request message being represented.
            </summary>
        </member>
        <member name="M:KafkaNet.IKafkaRequest`1.Encode">
            <summary>
            Encode this request into the Kafka wire protocol.
            </summary>
            <returns>Byte[] representing the binary wire protocol of this request.</returns>
        </member>
        <member name="M:KafkaNet.IKafkaRequest`1.Decode(System.Byte[])">
            <summary>
            Decode a response payload from Kafka into an enumerable of T responses. 
            </summary>
            <param name="payload">Buffer data returned by Kafka servers.</param>
            <returns></returns>
        </member>
        <member name="T:KafkaNet.DefaultTraceLog">
            <summary>
            This class simply logs all information out to the Trace log provided by windows.  
            The reason Trace is being used as the default it to remove extenal references from
            the base kafka-net package.  A proper logging framework like log4net is recommended.
            </summary>
        </member>
        <member name="T:KafkaNet.KafkaTcpSocket">
            <summary>
            The TcpSocket provides an abstraction from the main driver from having to handle connection to and reconnections with a server.
            The interface is intentionally limited to only read/write.  All connection and reconnect details are handled internally.
            </summary>
        </member>
        <member name="M:KafkaNet.KafkaTcpSocket.#ctor(KafkaNet.IKafkaLog,KafkaNet.Model.KafkaEndpoint,System.Nullable{System.TimeSpan})">
            <summary>
            Construct socket and open connection to a specified server.
            </summary>
            <param name="log">Logging facility for verbose messaging of actions.</param>
            <param name="endpoint">The IP endpoint to connect to.</param>
            <param name="maximumReconnectionTimeout">The maximum time to wait when backing off on reconnection attempts.</param>
        </member>
        <member name="P:KafkaNet.KafkaTcpSocket.Endpoint">
            <summary>
            The IP Endpoint to the server.
            </summary>
        </member>
        <member name="M:KafkaNet.KafkaTcpSocket.ReadAsync(System.Int32)">
            <summary>
            Read a certain byte array size return only when all bytes received.
            </summary>
            <param name="readSize">The size in bytes to receive from server.</param>
            <returns>Returns a byte[] array with the size of readSize.</returns>
        </member>
        <member name="M:KafkaNet.KafkaTcpSocket.ReadAsync(System.Int32,System.Threading.CancellationToken)">
            <summary>
            Read a certain byte array size return only when all bytes received.
            </summary>
            <param name="readSize">The size in bytes to receive from server.</param>
            <param name="cancellationToken">A cancellation token which will cancel the request.</param>
            <returns>Returns a byte[] array with the size of readSize.</returns>
        </member>
        <member name="M:KafkaNet.KafkaTcpSocket.WriteAsync(KafkaNet.KafkaDataPayload)">
            <summary>
            Convenience function to write full buffer data to the server.
            </summary>
            <param name="payload">The buffer data to send.</param>
            <returns>Returns Task handle to the write operation with size of written bytes..</returns>
        </member>
        <member name="M:KafkaNet.KafkaTcpSocket.WriteAsync(KafkaNet.KafkaDataPayload,System.Threading.CancellationToken)">
            <summary>
            Write the buffer data to the server.
            </summary>
            <param name="payload">The buffer data to send.</param>
            <param name="cancellationToken">A cancellation token which will cancel the request.</param>
            <returns>Returns Task handle to the write operation with size of written bytes..</returns>
        </member>
        <member name="M:KafkaNet.KafkaTcpSocket.ReEstablishConnectionAsync">
            <summary>
            (Re-)establish the Kafka server connection.
            Assumes that the caller has already obtained the <c>_clientLock</c>
            </summary>
        </member>
    </members>
</doc>
